# Resume Coach — Methodology

An open-source framework that turns Claude Code into a complete career toolkit: structured experience management, targeted CV generation, interview coaching with progress tracking, and voice simulation for realistic practice.

## Table of Contents

- [Structured Experience Management](#structured-experience-management)
- [Targeted Resume Generation](#targeted-resume-generation)
- [Interview Coaching](#interview-coaching)
- [Answering Strategies](#answering-strategies)
- [Voice Simulation Pipeline](#voice-simulation-pipeline)
- [Progress Tracking](#progress-tracking)
- [Architecture](#architecture)

---

## Structured Experience Management

All professional data lives in versioned markdown files following consistent templates:

| Data type | File | What it captures |
|---|---|---|
| Projects | `data/projects/*.md` | One file per engagement: period, role, client, responsibilities, achievements, technologies, tags |
| Skills | `data/skills.md` | Grouped by category with experience levels |
| Certifications | `data/certifications.md` | Status tracking: active, expired, renewal pending |
| Companies | `data/companies.md` | Own business entities, if applicable (founding dates, purposes, outcomes) |
| Profile | `data/profile.md` | Contact, rates, availability, languages |
| Project index | `data/project-index.md` | Lightweight index for quick matching against job ads |

This is the **single source of truth**. Every other feature reads from here. When you finish a project, you add one markdown file and update the index — every future CV and coaching session automatically has the new data.

### Why markdown?

- Git-versioned, diffable, portable
- No vendor lock-in, no database, no app subscriptions
- Claude Code reads it natively — no adapters or plugins needed
- Human-readable as a fallback if you stop using the framework

---

## Targeted Resume Generation

An 11-step workflow ([resume-workflow.md](../framework/resume-workflow.md)) takes a job ad and produces a tailored CV:

1. **Analyse the role** — extract requirements, technologies, seniority, market
2. **Match from data** — scan the project index for relevant experience
3. **Read project details** — pull in the 3–6 most relevant projects
4. **Consult professional-identity** — use narrative framing and reframes to inform tone
5. **Tailor the summary** — rewrite the professional summary for this specific role
6. **Order by relevance** — most relevant projects first, not just chronological
7. **Adjust skill emphasis** — highlight what matches, de-emphasise what doesn't
8. **Choose language** — match the language of the job posting (or the candidate's preferred language from `data/profile.md`)
9. **Choose format** — select the appropriate market format (see [style-guidelines.md](../framework/style-guidelines.md))
10. **Output** — clean markdown in `output/`, named by date and role
11. **Generate cheat sheet** — a companion quick-reference for recruiter calls, with coached answers mapped to each must-have requirement

**The key insight:** instead of maintaining one generic CV that you retrofit for each application, the system generates a role-specific CV every time, drawing from complete data. A CV for a product manager role pulls different projects and emphasises different achievements than one for a data engineer role — even though both draw from the same data.

### Quality gates

Two review skills catch problems before the CV goes out:

- **`/review-cv`** — fast quality-gate check against the target role
- **`/review-cv-deep`** — six parallel AI reviewers (recruiter, hiring manager, competitor analyst, skeptic, copy editor, source data auditor) each assess the CV from their perspective, producing a consolidated report with severity-rated issues and specific rewrites

The deep review also generates "Top 10 Probing Interview Questions" — the hardest questions this specific CV would trigger — which feed directly into the voice simulation pipeline.

### CV quality standards

The workflow includes a mandatory pre-output checklist covering:
- Keyword coverage against the job posting
- Product specificity (sub-product labels, not just parent product names)
- Claim integrity against source data
- No weakness admissions or hedging language
- Concurrent engagement explanations
- Team-fit signals (collaboration references)
- Formatting, tense, and language consistency

---

## Interview Coaching

Three coaching modes, each with a detailed methodology file:

### Recruiter Screening ([recruiter-screening.md](../framework/recruiter-screening.md))

Claude plays a recruiter conducting a 15–20 minute screening call. The recruiter's job is to check boxes and decide whether to forward you — your job is to survive the filter without disqualifying yourself.

Two difficulty levels:
- **Normal** — standard screening with coaching after each answer
- **Tough** — the recruiter has read the CV carefully and targets weak points. Includes compensation pushback, gap pressure tests, and direct pin-downs ("So you don't have [technology] production experience then")

Coaching happens out-of-character between exchanges. The session pauses, Claude gives specific feedback on what went wrong and provides a stronger version using your actual data, then you say "go on" to resume.

### Hiring Manager Mock Interview ([mock-interview.md](../framework/mock-interview.md))

Claude plays a technical hiring manager probing depth on architecture, decisions, and trade-offs. Questions escalate from warm-up through depth probes to pressure questions.

The hiring manager drills down: "Walk me through exactly how you implemented [specific claim from the CV]." Surface-level answers get exposed with follow-ups.

### Full Simulation ([full-simulation.md](../framework/full-simulation.md))

An uninterrupted conversation — no coaching breaks, no feedback mid-session. Tough mode is the default. This is the closest approximation to a real call.

After the conversation ends, a structured debrief covers: overall verdict, strongest/weakest answers, anti-pattern log, cheat sheet comparison (if used), confidence rating, and top 3 improvements.

### Coaching rules (all modes)

- **OOC pacing:** Coach never re-enters character until you say "go on" — the discussion after each answer is where the real learning happens
- **OOC safe space:** Admitting "I have no idea what that means" out-of-character is intelligence for the coach, not a performance failure
- **Real data, not generic advice:** stronger answer versions always reference your actual project files
- **No cheat sheet access:** the coach evaluates against raw data, not your prepared scripts — so flaws in the scripts get caught

---

## Answering Strategies

Six quick-reference technique files in [`framework/answering-strategies/`](../framework/answering-strategies/) for handling common interview pressure points. Each has a Quick Overview section for fast scanning before calls.

### 1. Blank Mind Protocol ([link](../framework/answering-strategies/behavioral-questions-without-prepared-example.md))

What to do when asked "Tell me about a time..." and you can't recall a specific example.

Four escape paths:
1. **Specific example** — you do have one, it just needs a moment to surface
2. **Pattern answer** — "What I typically do in that situation is..."
3. **Honest pivot** — "I haven't faced that exact scenario, but here's the closest..."
4. **Clarifying question** — buy time and narrow the scope

### 2. Gap Reframing ([link](../framework/answering-strategies/gap-reframing.md))

How to address missing skills without disqualifying yourself.

Pattern: **Acknowledge** (don't deny) → **Pivot** (to what you do have) → **Question back** (to reveal if the gap actually matters)

### 3. Pin-Down Defense ([link](../framework/answering-strategies/pin-down-defense.md))

How to handle when the interviewer restates your gap as a closed fact: "So you haven't done X."

This is a confidence test, not fact-finding. The coached response: "Not [X] specifically, but I [adjacent strength]. [Question back that reveals if the gap matters]."

### 4. Question-Back Technique ([link](../framework/answering-strategies/question-back-technique.md))

How to turn questions around to reveal real requirements and buy thinking time. Strategic, not evasive.

### 5. Anti-Patterns Checklist ([link](../framework/answering-strategies/anti-patterns.md))

60-second pre-call negative checklist. The things NOT to do:
- Volunteering negatives unprompted
- Essay structure (verdict last instead of first)
- Over-explaining technical details to non-technical recruiters
- Confirming the interviewer's concern
- Apologising instead of contextualising

### 6. Direct Answer Structure ([link](../framework/answering-strategies/direct-answer-structure.md))

Answer first, explain second, then stop. Fixes the "essay structure" anti-pattern where the verdict comes last and the listener has already tuned out.

---

## Voice Simulation Pipeline

A three-step workflow for realistic spoken practice:

```
/voice-export ──→ Claude App (voice) ──→ /debrief
   generate           practise             analyse
   prompt             by speaking          transcript
```

### Step 1: Generate (`/voice-export`)

Takes a CV file and job ad URL. Produces a self-contained recruiter simulation prompt — complete with persona, question pool (drawing from the deep review if available), call flow, and all context baked in.

The prompt is completely self-contained: no file access needed in the voice app. You paste it into a voice-capable AI app (like the Claude mobile app) and start talking.

### Step 2: Practise (voice app)

You speak out loud. No typing, no pauses for coaching. As close to a real phone screen as possible.

### Step 3: Debrief (`/debrief`)

Paste the transcript back into Claude Code. The debrief skill:
- Parses the transcript into Q&A pairs
- Rates each answer (1–5) with trust/credibility impact
- Compares against coached answers from your coaching files
- Identifies every triggered anti-pattern
- Generates a recruiter assessment (checkbox match + trust/credibility)
- Logs the session to the progress tracker

---

## Progress Tracking

Structured scorecards in `coaching/progress-recruiter/` and `coaching/progress-interview/` track improvement across sessions:

- **Anti-pattern frequency counts** — each pattern is tracked with occurrence count, last-seen date, and trend arrow (improving/stable/worsening)
- **Per-session logs** — specific examples, coaching notes, strongest/weakest answers, focus areas for next session
- **Session index** — table linking to each session file with date, role, mode, and confidence rating
- **Coached answers** — refined phrasings that get updated as sessions reveal better ways to say things

This turns interview preparation from "I feel more confident" into measurable data: anti-pattern X fired 4 times in session 1, twice in session 2, zero in session 3.

---

## Architecture

```
CLAUDE.md                        ← Orchestration brain: points Claude to the right files
framework/                       ← Methodology (reusable, no personal data)
  ├── resume-workflow.md          ← 11-step CV generation workflow
  ├── interview-workflow.md       ← Session routing and coaching rules
  ├── recruiter-screening.md      ← Recruiter coaching methodology
  ├── mock-interview.md           ← Hiring manager coaching methodology
  ├── full-simulation.md          ← Uninterrupted simulation + debrief
  ├── style-guidelines.md         ← Tone, language, format conventions
  ├── voice-export.md             ← Voice prompt generation rules
  └── answering-strategies/       ← Six interview technique files
data/                            ← Professional experience (private to the user)
  ├── projects/*.md               ← One file per engagement
  ├── skills.md, certifications.md, profile.md, etc.
  ├── project-index.md            ← Quick-match index
  ├── professional-identity.md           ← Identity, strengths, narrative patterns
  └── coaching/                   ← Self-awareness notes, insights
coaching/                        ← Coaching outputs and progress (private)
  ├── coached-answers.md          ← Refined spoken phrasings
  ├── progress-recruiter/         ← Session logs + scorecard
  └── progress-interview/         ← Session logs + scorecard
.claude/skills/                  ← Claude Code skill definitions (automation entry points)
  ├── import-cv/                  ← /import-cv skill (CV data extraction + merge)
  ├── extract-identity/           ← /extract-identity skill (professional self-discovery)
  ├── voice-export/               ← /voice-export skill
  ├── debrief/                    ← /debrief skill
  ├── review-cv/                  ← /review-cv skill (fast quality gate)
  ├── review-cv-deep/             ← /review-cv-deep skill (6-perspective review)
  └── scan-jobs/                  ← /scan-jobs skill (job portal scanner)
tools/                           ← Python utilities
  ├── convert_pdfs.py             ← PDF-to-text extractor
  └── md_to_pdf.py                ← Markdown CV → styled PDF
output/                          ← Generated CVs, cheat sheets, review reports
```

### Separation of concerns

- **`framework/`** is shareable and reusable. It contains no personal data — only methodology.
- **`data/`** and **`coaching/`** are personal. Someone forking the repo would keep the framework, delete these, and populate them with their own experience.
- **`CLAUDE.md`** is the routing layer. It describes the repo structure, data conventions, content exclusion rules, and tells Claude which framework file to load for each type of task. Without it, Claude would need to rediscover the structure every session.
- **`.claude/skills/`** define automation entry points — multi-step workflows triggered by slash commands (e.g., `/voice-export`, `/debrief`).

### Data flow

```
Job ad ──→ /scan-jobs ──→ Fit assessment
           (or manual paste)

Job ad ──→ Resume workflow ──→ CV in output/
       └─→ Cheat sheet in output/

CV ──→ /review-cv ──→ Fast quality gate
   └─→ /review-cv-deep ──→ 6-perspective report + interview questions

CV + job ad ──→ /voice-export ──→ Voice prompt (paste into voice app)
                                      │
                        Transcript ←───┘
                            │
                     /debrief ──→ Session analysis ──→ Progress tracker
                                                   └─→ Coached answers update

Role ──→ Coaching session (recruiter/HM/full-sim) ──→ Progress tracker
                                                   └─→ Coached answers update
```
